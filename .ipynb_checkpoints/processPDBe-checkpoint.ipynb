{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07373d8f-1ba6-465a-9eb2-fb607d608c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from itertools import batched\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841c5fb5-76de-465e-84b4-29aa4aed8502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in list of pdb codes for initial consideration\n",
    "pdbCodeFile = './pdbListAll.txt'\n",
    "\n",
    "# file contains comma separated list of pdb ids\n",
    "with open(pdbCodeFile) as f:\n",
    "    fileRead=f.read()\n",
    "pdbCodes = fileRead.strip().split(',')\n",
    "\n",
    "'''\n",
    "# dsv file with one column labeled 'pdbid'\n",
    "df = pd.read_csv(pdbCodeFile)\n",
    "pdbCodes=list(df['pdbid'])\n",
    "'''\n",
    "\n",
    "pdbCodes = pdbCodes[:1500]\n",
    "\n",
    "print(len(pdbCodes),'codes\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108a4350-b4b8-4802-9926-5e6e5338e065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download multiple entries, taking care that PDBe only allows batches up to 1000 at a time\n",
    "batchSize = 100  # must be less than 1000\n",
    "\n",
    "urlPrefix = 'https://www.ebi.ac.uk/pdbe/api/pdb/entry/summary/'\n",
    "pdbCodesBatched = batched( pdbCodes, batchSize ) # first separate list of codes into batches of 1000 \n",
    "reportDict = {}\n",
    "for batch in pdbCodesBatched:\n",
    "    print('downloading batch...', end='')\n",
    "    codeString = ','.join(batch)\n",
    "    report=requests.post(urlPrefix,data=codeString)\n",
    "    reportDict.update( json.loads(report.text) )\n",
    "    print(len(reportDict),'total entries')\n",
    "print(len(reportDict),'entries downloaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c02c0b-0af8-40c7-8f22-da9d4003d901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create summary dataframe from downloaded dictionary\n",
    "\n",
    "# keys in downloaded dictionary\n",
    "entryKeys = ['title', 'processing_site', 'deposition_site', 'deposition_date', 'release_date', 'revision_date', \\\n",
    "             'experimental_method_class', 'experimental_method', 'split_entry', 'related_structures', 'entry_authors', \\\n",
    "             'number_of_entities', 'assemblies']\n",
    "\n",
    "# keys with numerical, string or list values\n",
    "simpleKeys = ['title', 'deposition_date', 'experimental_method', 'related_structures']\n",
    "\n",
    "# keys of the sub-dictionaries that are the values associated with keys 'number_of_entities' and 'assemblies'\n",
    "entityKeys = ['water', 'polypeptide', 'dna', 'rna', 'dna/rna', 'sugar', 'ligand', 'carbohydrate_polymer', 'other']\n",
    "assemblyKeys = ['assembly_id', 'name', 'form']\n",
    "\n",
    "# columns (keys) of summary dataframe (dictionary)\n",
    "dataKeys = ['pdbid'] + simpleKeys + entityKeys + ['assemblies'] + assemblyKeys\n",
    "\n",
    "dataDict = { k:[] for k in dataKeys } \n",
    "for pdbid,entry in reportDict.items():\n",
    "    dataDict['pdbid'].append(pdbid)\n",
    "    for k in simpleKeys:\n",
    "        dataDict[k].append(entry[0][k])\n",
    "    for k in entityKeys:\n",
    "        dataDict[k].append(entry[0]['number_of_entities'][k])\n",
    "    dataDict['assemblies'].append(len(entry[0]['assemblies']))\n",
    "\n",
    "    # now go through the assemblies and extract data from preferred assembly: the Protein Data Bank in Europe (PDBe)\n",
    "    # defines the preferred assembly as the smallest assembly containing all polymeric entities.\n",
    "\n",
    "    for d in entry[0]['assemblies']:\n",
    "        if d['preferred']:\n",
    "            for ak in assemblyKeys:\n",
    "                dataDict[ak].append(d[ak])\n",
    "\n",
    "dataDf = pd.DataFrame(dataDict)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161e8c68-6de6-40d1-96e3-b1b1ca90e144",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f2fc43-5421-4e30-ad08-2264057da1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDf['assembly_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8295c144-258a-429a-b9bd-e4f258b114a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDf[ dataDf['assemblies'] >4 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db2f6de-f5e3-4442-be9f-30b016a917e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2878f2-9ec3-45ce-a41c-d9927388db1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic=reportDict['1c9b'][0]['assemblies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b372d191-2676-41df-8559-0b1a187919b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dic:\n",
    "    print(d['preferred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd82fe92-9157-453d-8141-64742e8bb842",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dic:\n",
    "    if d['preferred']:\n",
    "        print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f3859e-36a6-4bbc-ae41-de4e88c32411",
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in it.batched(a,3):\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ff85ba-7c82-4ce1-a270-6a967131435a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDf[ dataDf['pdbid']=='2oyq'][\n",
    "\n",
    "\n",
    "#dataDf['pdbid','assembly_id']]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e482a793-ca73-4d42-b9a3-6460e6bf430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download preferred assembly files\n",
    "assemblyDirectory = '../DATA/db/assemblies'\n",
    "\n",
    "os.makedirs(assemblyDirectory,exist_ok=True)\n",
    "for i in dataDf[ dataDf['assembly_id'] == '4' ].index:\n",
    "    code=dataDf.at[i,'pdbid']\n",
    "    assembly=dataDf.at[i,'assembly_id']\n",
    "    fileName = code + '-assembly' + assembly + '.cif'\n",
    "    url = 'https://files.rcsb.org/download/' + fileName\n",
    "    download = requests.get(url)\n",
    "    print(url)\n",
    "    with open( os.path.join(assemblyDirectory,fileName), 'w' ) as f:\n",
    "        f.write( download.text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ba1dcc-b2c4-4378-a45b-197a08e6642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDf[ dataDf['assembly_id'] == '4' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7ed859-003c-41a7-804f-720085bd52e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDf.describe("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a3b859-bbe6-44f6-ba26-a8e344d89b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDf.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030cbb23-f4d8-40ab-a6e5-a87dc9b4f6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaf897c-b309-4bd9-8710-b8bd0840df42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
