{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de89867b-be63-4f3f-83c1-972fd8b7b3a7",
   "metadata": {},
   "source": [
    "## pdbEntryAnalysis - monomer:palindrome interactions\n",
    "#### download and analyse pdb entries, creates dataframes for analysis that can be used in creating a data set for DNA-protein structure ML\n",
    "##### notes: sequence data should be taken from fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07373d8f-1ba6-465a-9eb2-fb607d608c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.PDB import PDBList                  # fetches/saves PDB data\n",
    "from Bio.PDB.MMCIF2Dict import MMCIF2Dict    # parses data in mmCIF files\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd634e2-e2bc-4a55-b3dd-62aad9909b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map CIF tokens onto dictionary keys. some tokens are repeated in the asu and the assembly, some are not, \n",
    "# the assembly can have fewer instances of entities. also, some are not present in assembly, \n",
    "# like title and id, src, etc. so we need to grab some from asu and some from assembly.\n",
    "# warning: some tokens repeated in asu and assembly have different values in the two files!\n",
    "# also: not all tokens of interest appear in all entries.\n",
    "\n",
    "# in definitions below, key is name of field (column) in database (dataframe), and value is the CIF token.\n",
    "# usually tokens from asu entry are all single element entries -- some exceptions\n",
    "# 1) 'gene': '_entity_src_gen.pdbx_gene_src_gene'\n",
    "# 2) 'species': '_entity_src_gen.pdbx_gene_src_scientific_name'\n",
    "\n",
    "asuTokens = { 'pdbid': '_entry.id',\\\n",
    "            'date': '_pdbx_database_status.recvd_initial_deposition_date',\\\n",
    "            'method': '_exptl.method',\\\n",
    "             'title': '_struct.title',\\\n",
    "            'gene': '_entity_src_gen.pdbx_gene_src_gene',\\\n",
    "             'species': '_entity_src_gen.pdbx_gene_src_scientific_name',\\\n",
    "             'keywords': '_struct_keywords.pdbx_keywords',\\\n",
    "            'text': '_struct_keywords.text'\n",
    "          }\n",
    "# all keys from assembly are lists of multiple entries\n",
    "# the lengths of the following (all from _entity_poly) should be 2 : \n",
    "#    1) 'polyid': '_entity_poly.entity_id'\n",
    "#    2) 'polytype': '_entity_poly.type'\n",
    "#    3) 'seq': '_entity_poly.pdbx_seq_one_letter_code_can'\n",
    "#    4) 'polystrand': '_entity_poly.pdbx_strand_id',\\\n",
    "# the lengths of the following (all from _entity) should be AT LEAST 2 and ALL EQUAL:\n",
    "#    5) 'entityid': '_entity.id'\n",
    "#    6) 'entitytype': '_entity.type'\n",
    "#    7) 'descr': '_entity.pdbx_description'\n",
    "#    8) 'MW': '_entity.formula_weight'\n",
    "#    9) 'number': '_entity.pdbx_number_of_molecules'\n",
    "\n",
    "assemblyTokens = {'polyid': '_entity_poly.entity_id',\\\n",
    "                'polytype': '_entity_poly.type',\\\n",
    "                'seq': '_entity_poly.pdbx_seq_one_letter_code_can',\\\n",
    "                  'polystrand': '_entity_poly.pdbx_strand_id',\\\n",
    "                'entityid': '_entity.id',\\\n",
    "                'entitytype': '_entity.type',\\\n",
    "                'descr': '_entity.pdbx_description',\\\n",
    "                'MW': '_entity.formula_weight',\\\n",
    "                'number': '_entity.pdbx_number_of_molecules'\n",
    "               }\n",
    "columnNames = list(asuTokens.keys())+list(assemblyTokens.keys())  # combine all keys into one list for dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304644fb-59cf-45bf-9599-9a67815d79eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in list of pdb codes for initial consideration\n",
    "pdbCodeFile = './pdbList_monomer:palindrome.txt'\n",
    "with open(pdbCodeFile) as f:\n",
    "    fileRead=f.read()\n",
    "pdbCodes = fileRead.strip().split(',')\n",
    "print(len(pdbCodes),'codes\\n',pdbCodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a190325d-9203-44db-b4c7-4386ac2a7f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaa0a98-ebb8-4667-b846-df6427069283",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define data directories. fetch both asu and assembly files, then run check\n",
    "asuDirectory      = 'asu'\n",
    "assemblyDirectory = 'assembly'\n",
    "\n",
    "# use Biopython to handle fetching - will create directories if necessary\n",
    "pdblist = PDBList()\n",
    "pdblist.download_pdb_files(pdbCodes,pdir=asuDirectory,file_format='mmCif')\n",
    "for pdbCode in pdbCodes:\n",
    "    pdblist.retrieve_assembly_file(pdbCode,1,pdir=assemblyDirectory,file_format='mmCif') # number is which assembly\n",
    "\n",
    "# run a check on files:\n",
    "asuList = os.listdir(asuDirectory)\n",
    "assemblyList = os.listdir(assemblyDirectory)\n",
    "print(len(pdbCodes),'PDB codes in list')\n",
    "for code in pdbCodes:\n",
    "    if not code+'.cif' in asuList:\n",
    "        print(code, 'not in', asuDirectory)\n",
    "print( len(asuList), 'files in', asuDirectory, 'directory')\n",
    "for code in pdbCodes:\n",
    "    if not code+'-assembly1.cif' in assemblyList:\n",
    "        print(code, 'not in', assemblyDirectory)\n",
    "print( len(assemblyList), 'files in', assemblyDirectory, 'directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3530db6-2876-4524-84ce-a9a9ff8453ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse each pair of mmCIF files (one for asu, one for assembly), and map values to dictionaries\n",
    "dfDict = { k:[] for k in columnNames }      # holds the values for each entry\n",
    "lengthDict = { k:[] for k in columnNames }  # holds counts of each value (length of list)\n",
    "\n",
    "# create the dictionaries of the values I want from the asu header and the bio-assembly header\n",
    "for pdbCode in pdbCodes:\n",
    "    print(pdbCode,': START RECORD ---',end =' ')\n",
    "    asucif       = MMCIF2Dict(asuDirectory+'/'+pdbCode+'.cif')\n",
    "    assemblycif  = MMCIF2Dict(assemblyDirectory+'/'+pdbCode+'-assembly1.cif')\n",
    "    for k,v in asuTokens.items():          # iterate over asu token/value pairs\n",
    "        try:\n",
    "            value = asucif[v]\n",
    "        except:\n",
    "            value = []\n",
    "        dfDict[k].append(value)\n",
    "        lengthDict[k].append(len(value))\n",
    "    for k,v in assemblyTokens.items():      # iterate over bio-assembly token/value pairs\n",
    "        try:\n",
    "            value = assemblycif[v]\n",
    "        except:\n",
    "            value = []\n",
    "        dfDict[k].append(value)\n",
    "        lengthDict[k].append(len(value))\n",
    "    print('END RECORD.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac038036-eaa4-48af-a29d-2636fdab5f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframes and \n",
    "df=pd.DataFrame(dfDict)\n",
    "lengthDf=pd.DataFrame(lengthDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c925e943-0637-4292-94a7-52aea1e29766",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# examine\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdffe2d8-3f61-449c-a80e-2f9363aaee93",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengthDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79512684-3432-4b94-9bad-82a36e3f6e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# which fields have multiple numbers of entries? This code will list each column label and a set of\n",
    "# possible values for the lengths of the entries. e.g., pdbid should have just {1}, but gene could have more.\n",
    "# expectations for monomer:palindrome structures --- see cell near top\n",
    "# note: polyid, polytype, seq, polystrand should all =2\n",
    "# note: entityid, entitytype, descr, MW, number should all be equal and >=2\n",
    "\n",
    "for k in lengthDf.columns:\n",
    "    print(k,'\\t',set(lengthDf[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ecebb6-5287-4eba-98a5-4d9971a93e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine these variations \n",
    "lengthDf.hist(['gene','species','polyid','polytype','seq','polystrand'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fae4a95-bcac-4b9c-9c3a-408c321a5a6a",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### now let's find structures to exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86155c5c-f607-4d12-b478-eaa4551ce7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first check for _entity_poly values not =2 \n",
    "examineColumns = [ 'polyid',\\\n",
    "                 'polytype',\\\n",
    "                  'seq',\\\n",
    "                'polystrand',\\\n",
    "                 ]\n",
    "dfExclude = {}\n",
    "for k in examineColumns:\n",
    "    dfExclude[k] = df[ lengthDf[k]!=2 ]\n",
    "    print(dfExclude[k]['pdbid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4101d92-53b7-44df-8ea6-63073262f006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1g3x is a peptide drug --- exclude\n",
    "# 5xfp assembly 1 lacks dna, use assembly 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58e33ed-7877-4323-bd78-d72a483656ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now check for _entity values  <2 and for equality of length of all _entity values\n",
    "examineColumns = [ 'entityid',\\\n",
    "                 'entitytype',\\\n",
    "                  'descr',\\\n",
    "                'MW',\\\n",
    "                  'number',\\\n",
    "                 ]\n",
    "dfExclude = {}\n",
    "for k in examineColumns:\n",
    "    dfExclude[k] = df[ lengthDf[k]<2 ]\n",
    "    print(dfExclude[k]['pdbid'])\n",
    "\n",
    "dfExclude = {}\n",
    "for k in examineColumns:\n",
    "    for kk in examineColumns:\n",
    "        dfExclude[(k,kk)] = df[ lengthDf[k] != lengthDf[kk] ]\n",
    "        print('error: ',k,kk,'\\n',dfExclude[(k,kk)]['pdbid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffa0e99-2b19-48c6-bbf9-0b5cc181ebfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cea204b-5b4c-412e-804b-b4c38d323380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's double check for number of chains in assembly.This can be done by looking at polystrand\n",
    "\n",
    "examineList=[]\n",
    "removeIndex=[]\n",
    "for index,item in zip(df.index,df['polystrand']):\n",
    "    itemsplit = [s.split(',') for s in item]\n",
    "    itemlength = [len(i) for i in itemsplit]\n",
    "    if itemlength != [1,2] and itemlength != [2,1]:\n",
    "        print(index, df.iloc[index]['pdbid'],itemlength)\n",
    "        examineList.append(df.iloc[index]['pdbid'][0].lower() )\n",
    "        removeIndex.append(index )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dfcc15-c173-492b-ae22-bc3a3aeb27ba",
   "metadata": {},
   "source": [
    "###### 6 ['1EFA'] [2, 2]   lac repressor dimer bound to duplex - exclude\n",
    "###### 8 ['1G3X'] [2]    peptide drug - exclude \n",
    "###### 34 ['2PY5'] [3, 1]    dnap bound to non-duplex dna - exclude\n",
    "###### 42 ['3MLN'] [2, 2]    homodimer:palindrome - exclude\n",
    "###### 51 ['3VH0'] [2, 2]   2 beta-propellors bound to ends of dna duplex - exclude\n",
    "###### 57 ['4GZ1'] [1, 1]   2 proteins bound to duplex ends - exclude\n",
    "###### 65 ['4JRP'] [1, 1]   non-duplex dna - exclude\n",
    "###### 66 ['4JRQ'] [1, 1]      non-duplex dna - exclude\n",
    "###### 67 ['4JS4'] [1, 1]   non-duplex dna - exclude\n",
    "###### 81 ['4QQW'] [1, 1]   non-duplex dna - exclude\n",
    "###### 82 ['4QQX'] [1, 1]   non-duplex dna - exclude\n",
    "###### 83 ['4QQY'] [1, 1]   non-duplex dna - exclude\n",
    "###### 84 ['4QQZ'] [1, 1]      non-duplex dna - exclude\n",
    "###### 98 ['5NW9'] [2, 2]   2 proteins bound to duplex ends - exclude\n",
    "###### 99 ['5NWA'] [2, 2]   2 proteins bound to duplex ends - exclude\n",
    "###### 100 ['5T1J'] [2, 4]   1 homodimer bound to 2 DNAs---can take assembly 2 for one protein-dna pair - USE\n",
    "###### 109 ['5XFP'] [1]      need assembly 2 \n",
    "###### 128 ['6FQQ'] [3, 2]    need assembly 2\n",
    "###### 147 ['7LH9'] [1, 4]   monomer bound to DSB -- exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a026075a-26fd-4902-8626-567cd6759dda",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [],
   "source": [
    "# edit remove list\n",
    "print('before edit:',removeIndex)\n",
    "keepList= [100,109,128]\n",
    "print('to keep:', keepList)\n",
    "for x in keepList:\n",
    "    removeIndex.remove(x)\n",
    "print('after edit:',removeIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b69fb42-8388-48c6-bcad-927f1748fd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfExclude = df.drop(removeIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9efdbeb-d0b3-4d63-9274-ed491237d768",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfExclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c66bca1-0a20-46ac-a20e-915dcc36005b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's double check for number of chains in dfExclude.This can be done by looking at polystrand\n",
    "\n",
    "for index,item in zip(dfExclude.index,dfExclude['polystrand']):\n",
    "    itemsplit = [s.split(',') for s in item]\n",
    "    itemlength = [len(i) for i in itemsplit]\n",
    "    if itemlength != [1,2] and itemlength != [2,1]:\n",
    "        print(index, df.iloc[index]['pdbid'],itemlength)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3241e180-2489-447f-b897-f3e843fc127e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now download any new assemblies needed:\n",
    "newAssemblyList = ['5T1J','5XFP','6FQQ'] \n",
    "assembly = 2\n",
    "for pdbCode in newAssemblyList:\n",
    "    pdblist.retrieve_assembly_file(pdbCode,assembly,pdir=assemblyDirectory,file_format='mmCif') # number is which assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ee18ea-6f57-44eb-9557-ea26366fd04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this strange pythonism will remove brackets from list pdbid's in dataframe\n",
    "newPdbCodes= [x for [x] in list(dfExclude['pdbid'])]\n",
    "assemblies = []\n",
    "for code in newPdbCodes:\n",
    "    if code in newAssemblyList:\n",
    "        assemblies.append(2)\n",
    "    else:\n",
    "        assemblies.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f887e11e-b0de-415c-9bf0-ef12ceb7d7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a,c in zip(assemblies,newPdbCodes):\n",
    "    print(a,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693c4cf3-e7da-47e3-a77d-496d6e5f7cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "newPdbDict={ 'pdbid': newPdbCodes, 'assembly': assemblies }\n",
    "dfNewPdb = pd.DataFrame(newPdbDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f58de6-64a8-48d2-a85c-e3bc2c0bbb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNewPdb[ dfNewPdb['assembly']==2 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878ff577-69c3-4d6c-98a8-d485f31d30e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNewPdb.to_csv('monomer:palindrome_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02823951-7dcd-43ff-98dd-9223ba20e522",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
