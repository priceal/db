{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de89867b-be63-4f3f-83c1-972fd8b7b3a7",
   "metadata": {},
   "source": [
    "## prep of class: monomer:palindrome \n",
    "#### download and analyse pdb entries, creates dataframes for analysis that can be used in creating a data set for DNA-protein structure ML\n",
    "##### notes: sequence data should be taken from fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07373d8f-1ba6-465a-9eb2-fb607d608c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.PDB import PDBList                  # fetches/saves PDB data\n",
    "from Bio.PDB.MMCIF2Dict import MMCIF2Dict    # parses data in mmCIF files\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd634e2-e2bc-4a55-b3dd-62aad9909b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map CIF tokens onto dictionary keys. some tokens are repeated in the asu and the assembly, some are not, \n",
    "# the assembly can have fewer instances of entities. also, some are not present in assembly, \n",
    "# like title and id, src, etc. so we need to grab some from asu and some from assembly.\n",
    "# warning: some tokens repeated in asu and assembly have different values in the two files!\n",
    "# also: not all tokens of interest appear in all entries.\n",
    "\n",
    "# in definitions below, key is name of field (column) in database (dataframe), and value is the CIF token.\n",
    "# usually tokens from asu entry are all single element entries -- some exceptions\n",
    "# 1) 'gene': '_entity_src_gen.pdbx_gene_src_gene'\n",
    "# 2) 'species': '_entity_src_gen.pdbx_gene_src_scientific_name'\n",
    "\n",
    "asuTokens = { 'pdbid': '_entry.id',\\\n",
    "            'date': '_pdbx_database_status.recvd_initial_deposition_date',\\\n",
    "            'method': '_exptl.method',\\\n",
    "             'title': '_struct.title',\\\n",
    "            'gene': '_entity_src_gen.pdbx_gene_src_gene',\\\n",
    "             'species': '_entity_src_gen.pdbx_gene_src_scientific_name',\\\n",
    "             'keywords': '_struct_keywords.pdbx_keywords',\\\n",
    "            'text': '_struct_keywords.text'\n",
    "          }\n",
    "# all keys from assembly are lists of multiple entries\n",
    "# the lengths of the following (all from _entity_poly) should be 2 : \n",
    "#    1) 'polyid': '_entity_poly.entity_id'\n",
    "#    2) 'polytype': '_entity_poly.type'\n",
    "#    3) 'seq': '_entity_poly.pdbx_seq_one_letter_code_can'\n",
    "#    4) 'polystrand': '_entity_poly.pdbx_strand_id',\\\n",
    "# the lengths of the following (all from _entity) should be AT LEAST 2 and ALL EQUAL:\n",
    "#    5) 'entityid': '_entity.id'\n",
    "#    6) 'entitytype': '_entity.type'\n",
    "#    7) 'descr': '_entity.pdbx_description'\n",
    "#    8) 'MW': '_entity.formula_weight'\n",
    "#    9) 'number': '_entity.pdbx_number_of_molecules'\n",
    "\n",
    "assemblyTokens = {'polyid': '_entity_poly.entity_id',\\\n",
    "                'polytype': '_entity_poly.type',\\\n",
    "                'seq': '_entity_poly.pdbx_seq_one_letter_code_can',\\\n",
    "                  'polystrand': '_entity_poly.pdbx_strand_id',\\\n",
    "                'entityid': '_entity.id',\\\n",
    "                'entitytype': '_entity.type',\\\n",
    "                'descr': '_entity.pdbx_description',\\\n",
    "                'MW': '_entity.formula_weight',\\\n",
    "                'number': '_entity.pdbx_number_of_molecules'\n",
    "               }\n",
    "columnNames = list(asuTokens.keys())+list(assemblyTokens.keys())  # combine all keys into one list for dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304644fb-59cf-45bf-9599-9a67815d79eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in list of pdb codes for initial consideration\n",
    "dfCodes = pd.read_csv('./monomer:palindrome_v1.csv')\n",
    "dfCodes[ dfCodes[ 'assembly' ] ==2 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a228304c-8181-4efc-911c-7a51124a4154",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pdbCodes = [ c.lower() for c in  list( dfCodes['pdbid' ] ) ]\n",
    "assemblies = list( dfCodes[ 'assembly' ] )\n",
    "print(len(pdbCodes),'codes\\n',pdbCodes)\n",
    "print(len(assemblies),'codes\\n',assemblies )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a53f76-7720-4c99-8e2c-aeb76aad3134",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define data directories. fetch both asu and assembly files, then run check\n",
    "asuDirectory      = 'asu'\n",
    "assemblyDirectory = 'assembly'\n",
    "\n",
    "# run a check on files:\n",
    "asuList = os.listdir(asuDirectory)\n",
    "assemblyList = os.listdir(assemblyDirectory)\n",
    "asuCodes = [ s.split('.')[0] for s in asuList ]\n",
    "assemblyCodes = [ s.split('-')[0] for s in assemblyList ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7166e3ab-ba3c-4300-b951-34da448620a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for code in pdbCodes:\n",
    "    if not code in asuCodes:\n",
    "        print(code, 'not in', asuDirectory)\n",
    "    if not code in assemblyCodes:\n",
    "        print(code, 'not in', assemblyDirectory)\n",
    "        \n",
    "print( len(asuList), 'files in', asuDirectory, 'directory')\n",
    "print( len(assemblyList), 'files in', assemblyDirectory, 'directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3530db6-2876-4524-84ce-a9a9ff8453ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse each pair of mmCIF files (one for asu, one for assembly), and map values to dictionaries\n",
    "dfDict = { k:[] for k in columnNames }      # holds the values for each entry\n",
    "lengthDict = { k:[] for k in columnNames }  # holds counts of each value (length of list)\n",
    "\n",
    "# create the dictionaries of the values I want from the asu header and the bio-assembly header\n",
    "for pdbCode,assembly in zip(pdbCodes,assemblies):\n",
    "    print(pdbCode,': START RECORD ---',end =' ')\n",
    "    asucif       = MMCIF2Dict(asuDirectory+'/'+pdbCode+'.cif')\n",
    "    assemblycif  = MMCIF2Dict(assemblyDirectory+'/'+pdbCode+'-assembly'+str(assembly)+'.cif')\n",
    "    for k,v in asuTokens.items():          # iterate over asu token/value pairs\n",
    "        try:\n",
    "            value = asucif[v]\n",
    "        except:\n",
    "            value = []\n",
    "        dfDict[k].append(value)\n",
    "        lengthDict[k].append(len(value))\n",
    "    for k,v in assemblyTokens.items():      # iterate over bio-assembly token/value pairs\n",
    "        try:\n",
    "            value = assemblycif[v]\n",
    "        except:\n",
    "            value = []\n",
    "        dfDict[k].append(value)\n",
    "        lengthDict[k].append(len(value))\n",
    "    print('END RECORD.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac038036-eaa4-48af-a29d-2636fdab5f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframes and \n",
    "df=pd.DataFrame(dfDict)\n",
    "lengthDf=pd.DataFrame(lengthDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdffe2d8-3f61-449c-a80e-2f9363aaee93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed6e2e8-75b7-4e4b-8175-a41ee7e40c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengthDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79512684-3432-4b94-9bad-82a36e3f6e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# which fields have multiple numbers of entries? This code will list each column label and a set of\n",
    "# possible values for the lengths of the entries. e.g., pdbid should have just {1}, but gene could have more.\n",
    "# expectations for monomer:palindrome structures --- see cell near top\n",
    "# note: polyid, polytype, seq, polystrand should all =2\n",
    "# note: entityid, entitytype, descr, MW, number should all be equal and >=2\n",
    "\n",
    "for k in lengthDf.columns:\n",
    "    print(k,'\\t',set(lengthDf[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ecebb6-5287-4eba-98a5-4d9971a93e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine these variations \n",
    "lengthDf.hist(['gene','species','polyid','polytype','seq','polystrand'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fae4a95-bcac-4b9c-9c3a-408c321a5a6a",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### now let's find structures to exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86155c5c-f607-4d12-b478-eaa4551ce7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first check for _entity_poly values not =2 \n",
    "examineColumns = [ 'polyid',\\\n",
    "                 'polytype',\\\n",
    "                  'seq',\\\n",
    "                'polystrand',\\\n",
    "                 ]\n",
    "dfExclude = {}\n",
    "for k in examineColumns:\n",
    "    dfExclude[k] = df[ lengthDf[k]!=2 ]\n",
    "    print(dfExclude[k]['pdbid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58e33ed-7877-4323-bd78-d72a483656ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now check for _entity values  <2 and for equality of length of all _entity values\n",
    "examineColumns = [ 'entityid',\\\n",
    "                 'entitytype',\\\n",
    "                  'descr',\\\n",
    "                'MW',\\\n",
    "                  'number',\\\n",
    "                 ]\n",
    "dfExclude = {}\n",
    "for k in examineColumns:\n",
    "    dfExclude[k] = df[ lengthDf[k]<2 ]\n",
    "    print(dfExclude[k]['pdbid'])\n",
    "\n",
    "dfExclude = {}\n",
    "for k in examineColumns:\n",
    "    for kk in examineColumns:\n",
    "        dfExclude[(k,kk)] = df[ lengthDf[k] != lengthDf[kk] ]\n",
    "        print('error: ',k,kk,'\\n',dfExclude[(k,kk)]['pdbid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cea204b-5b4c-412e-804b-b4c38d323380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's double check for number of chains in assembly.This can be done by looking at polystrand\n",
    "\n",
    "examineList=[]\n",
    "removeIndex=[]\n",
    "for index,item in zip(df.index,df['polystrand']):\n",
    "    itemsplit = [s.split(',') for s in item]\n",
    "    itemlength = [len(i) for i in itemsplit]\n",
    "    if itemlength != [1,2] and itemlength != [2,1]:\n",
    "        print(index, df.iloc[index]['pdbid'],itemlength)\n",
    "        examineList.append(df.iloc[index]['pdbid'][0].lower() )\n",
    "        removeIndex.append(index )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc824d62-13e0-466a-925f-959e1b15b1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "removeIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02823951-7dcd-43ff-98dd-9223ba20e522",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
